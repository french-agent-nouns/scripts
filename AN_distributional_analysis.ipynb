{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading of the 5 DSMs\n",
    "\n",
    "import gensim.models.keyedvectors as word2vec\n",
    "model1 = word2vec.KeyedVectors.load_word2vec_format('filepath/model1', binary=False, unicode_errors='ignore')\n",
    "model2 = word2vec.KeyedVectors.load_word2vec_format('filepath/model2', binary=False, unicode_errors='ignore')\n",
    "model3 = word2vec.KeyedVectors.load_word2vec_format('filepath/model3', binary=False, unicode_errors='ignore')\n",
    "model4 = word2vec.KeyedVectors.load_word2vec_format('filepath/model4', binary=False, unicode_errors='ignore')\n",
    "model5 = word2vec.KeyedVectors.load_word2vec_format('filepath/model5', binary=False, unicode_errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading of the data\n",
    "\n",
    "import re\n",
    "fileData = open('filepath/file')\n",
    "\n",
    "listData = []\n",
    "\n",
    "for Line in fileData:\n",
    "    Line = Line.rstrip('\\n')\n",
    "    listData.append(Line)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computation of the 100 nearest neighbors to a centroid over 5 DSMs\n",
    "\n",
    "import numpy \n",
    "import re\n",
    "vector1 = numpy.zeros(100)\n",
    "vector2 = numpy.zeros(100)\n",
    "vector3 = numpy.zeros(100)\n",
    "vector4 = numpy.zeros(100)\n",
    "vector5 = numpy.zeros(100)\n",
    "\n",
    "n_items=0\n",
    "\n",
    "for mCat in listData:\n",
    "    m = \"NC:\"+mCat\n",
    "    try:\n",
    "        m1_vector = model1[m.strip()]\n",
    "        vector1 = numpy.add(vector1,m1_vector)\n",
    "        m2_vector = model2[m.strip()]\n",
    "        vector2 = numpy.add(vector2,m2_vector)\n",
    "        m3_vector = model3[m.strip()]\n",
    "        vector3 = numpy.add(vector3,m3_vector)\n",
    "        m4_vector = model4[m.strip()]\n",
    "        vector4 = numpy.add(vector4,m4_vector)\n",
    "        m5_vector = model5[m.strip()]\n",
    "        vector5 = numpy.add(vector5,m5_vector)\n",
    "        n_items += 1\n",
    "    except KeyError as e:\n",
    "        continue\n",
    "vector1 = numpy.divide(vector1,n_items)\n",
    "vector2 = numpy.divide(vector2,n_items)\n",
    "vector3 = numpy.divide(vector3,n_items)\n",
    "vector4 = numpy.divide(vector4,n_items)\n",
    "vector5 = numpy.divide(vector5,n_items)\n",
    "\n",
    "listVec = {}\n",
    "\n",
    "OrderedDict = {}\n",
    "for m in model1.vocab:\n",
    "    if m in model2.vocab and m in model3.vocab and m in model4.vocab and m in model5.vocab:\n",
    "        try:\n",
    "            val1 = abs(numpy.divide(numpy.dot(model1[m.strip()],vector1),numpy.dot(numpy.linalg.norm(model1[m.strip()]),numpy.linalg.norm(vector1))))\n",
    "            val2 = abs(numpy.divide(numpy.dot(model2[m.strip()],vector2),numpy.dot(numpy.linalg.norm(model2[m.strip()]),numpy.linalg.norm(vector2))))\n",
    "            val3 = abs(numpy.divide(numpy.dot(model3[m.strip()],vector3),numpy.dot(numpy.linalg.norm(model3[m.strip()]),numpy.linalg.norm(vector3))))\n",
    "            val4 = abs(numpy.divide(numpy.dot(model4[m.strip()],vector4),numpy.dot(numpy.linalg.norm(model4[m.strip()]),numpy.linalg.norm(vector4))))\n",
    "            val5 = abs(numpy.divide(numpy.dot(model5[m.strip()],vector5),numpy.dot(numpy.linalg.norm(model5[m.strip()]),numpy.linalg.norm(vector5))))\n",
    "            aveVal = (val1+val2+val3+val4+val5)/5\n",
    "            aveVal = str(aveVal)\n",
    "            if not re.search(\"e-0\", aveVal):\n",
    "                listVec[m] = aveVal\n",
    "        except KeyError as e:\n",
    "            continue\n",
    "        \n",
    "sorted_by_value = sorted(listVec.items(), reverse=True, key=lambda kv: kv[1])\n",
    "print(len(sorted_by_value))\n",
    "for i in range(0,100):\n",
    "    word = sorted_by_value[i]\n",
    "    lemme = word[0]\n",
    "    prox = word[1]\n",
    "    output = lemme+\"\\t\"+prox\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average proximity score of X-ITs with each other or to Y-ITs\n",
    "# The computation of proximity score s to Y-ITs requires the preliminary loading of Y-ITs (see 2nd cell) - listDataY below\n",
    "\n",
    "fileOut = open('filepath/file', \"a\")\n",
    "\n",
    "for vCat in listData:\n",
    "    n_items = 0\n",
    "    v = \"NC:\"+vCat\n",
    "    globalAveProx = 0\n",
    "    if v not in model1.vocab:\n",
    "        continue\n",
    "    for wCat in listData:\n",
    "#    for wCat in listDataY:\n",
    "        if not wCat is vCat:\n",
    "            w = \"NC:\"+wCat\n",
    "            if w not in model1.vocab:\n",
    "                continue\n",
    "            n_items +=1\n",
    "            prox1 = model1.similarity(v,w)\n",
    "            prox2 = model2.similarity(v,w)\n",
    "            prox3 = model3.similarity(v,w)\n",
    "            prox4 = model4.similarity(v,w)\n",
    "            prox5 = model5.similarity(v,w)\n",
    "            aveProx = (abs(prox1)+abs(prox2)+abs(prox3)+abs(prox4)+abs(prox5))/5\n",
    "            globalAveProx = globalAveProx + aveProx\n",
    "\n",
    "    globalAveProx = globalAveProx/n_items\n",
    "    line = v+\"\\t\"+str(globalAveProx)+\"\\n\"\n",
    "    fileOut.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computation of proximity score of two centroids X and Y\n",
    "# Requires the loading of the list of Y-data - listDataY below\n",
    "\n",
    "import numpy \n",
    "import re\n",
    "x_vector_m1 = numpy.zeros(100)\n",
    "x_vector_m2 = numpy.zeros(100)\n",
    "x_vector_m3 = numpy.zeros(100)\n",
    "x_vector_m4 = numpy.zeros(100)\n",
    "x_vector_m5 = numpy.zeros(100)\n",
    "\n",
    "y_vector_m1 = numpy.zeros(100)\n",
    "y_vector_m2 = numpy.zeros(100)\n",
    "y_vector_m3 = numpy.zeros(100)\n",
    "y_vector_m4 = numpy.zeros(100)\n",
    "y_vector_m5 = numpy.zeros(100)\n",
    "\n",
    "n_x=0\n",
    "n_y = 0\n",
    "\n",
    "for mCat in listData:\n",
    "    m = \"NC:\"+mCat\n",
    "    try:\n",
    "        m1_vector = model1[m.strip()]\n",
    "        x_vector_m1 = numpy.add(x_vector_m1,m1_vector)\n",
    "        m2_vector = model2[m.strip()]\n",
    "        x_vector_m2 = numpy.add(x_vector_m2,m2_vector)\n",
    "        m3_vector = model3[m.strip()]\n",
    "        x_vector_m3 = numpy.add(x_vector_m3,m3_vector)\n",
    "        m4_vector = model4[m.strip()]\n",
    "        x_vector_m4 = numpy.add(x_vector_m4,m4_vector)\n",
    "        m5_vector = model5[m.strip()]\n",
    "        x_vector_m5 = numpy.add(x_vector_m5,m5_vector)\n",
    "        n_x += 1\n",
    "    except KeyError as e:\n",
    "        continue\n",
    "x_vector_m1 = numpy.divide(x_vector_m1,n_x)\n",
    "x_vector_m2 = numpy.divide(x_vector_m2,n_x)\n",
    "x_vector_m3 = numpy.divide(x_vector_m3,n_x)\n",
    "x_vector_m4 = numpy.divide(x_vector_m4,n_x)\n",
    "x_vector_m5 = numpy.divide(x_vector_m5,n_x)\n",
    "        \n",
    "for mCat in listDataY:\n",
    "    m = \"NC:\"+mCat\n",
    "    try:\n",
    "        m1_vector = model1[m.strip()]\n",
    "        y_vector_m1 = numpy.add(y_vector_m1,m1_vector)\n",
    "        m2_vector = model2[m.strip()]\n",
    "        y_vector_m2 = numpy.add(y_vector_m2,m2_vector)\n",
    "        m3_vector = model3[m.strip()]\n",
    "        y_vector_m3 = numpy.add(y_vector_m3,m3_vector)\n",
    "        m4_vector = model4[m.strip()]\n",
    "        y_vector_m4 = numpy.add(y_vector_m4,m4_vector)\n",
    "        m5_vector = model5[m.strip()]\n",
    "        y_vector_m5 = numpy.add(y_vector_m5,m5_vector)\n",
    "        n_y += 1\n",
    "    except KeyError as e:\n",
    "        continue\n",
    "y_vector_m1 = numpy.divide(y_vector_m1,n_y)\n",
    "y_vector_m2 = numpy.divide(y_vector_m2,n_y)\n",
    "y_vector_m3 = numpy.divide(y_vector_m3,n_y)\n",
    "y_vector_m4 = numpy.divide(y_vector_m4,n_y)\n",
    "y_vector_m5 = numpy.divide(y_vector_m5,n_y)\n",
    "        \n",
    "prox1 = abs(numpy.divide(numpy.dot(y_vector_m1,x_vector_m1),numpy.dot(numpy.linalg.norm(y_vector_m1),numpy.linalg.norm(x_vector_m1))))\n",
    "prox2 = abs(numpy.divide(numpy.dot(y_vector_m2,x_vector_m2),numpy.dot(numpy.linalg.norm(y_vector_m2),numpy.linalg.norm(x_vector_m2))))\n",
    "prox3 = abs(numpy.divide(numpy.dot(y_vector_m3,x_vector_m3),numpy.dot(numpy.linalg.norm(y_vector_m3),numpy.linalg.norm(x_vector_m3))))\n",
    "prox4 = abs(numpy.divide(numpy.dot(y_vector_m4,x_vector_m4),numpy.dot(numpy.linalg.norm(y_vector_m4),numpy.linalg.norm(x_vector_m4))))\n",
    "prox5 = abs(numpy.divide(numpy.dot(y_vector_m5,x_vector_m5),numpy.dot(numpy.linalg.norm(y_vector_m5),numpy.linalg.norm(x_vector_m5))))\n",
    "proxM = (prox1+prox2+prox3+prox4+prox5)/5\n",
    "print(proxM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computation of the HNs centroids\n",
    "# Needed for the computation of the average proximity scores of candidates to agentivity (see cell below)\n",
    "# Based on the sampled lists\n",
    "\n",
    "import re\n",
    "import numpy \n",
    "\n",
    "fileAN = open('filepath/file')\n",
    "fileDem = open('filepath/file')\n",
    "fileRel = open('filepath/file')\n",
    "filePhas = open('filepath/file')\n",
    "\n",
    "listAN = []\n",
    "listDem = []\n",
    "listRel = []\n",
    "listPhas = []\n",
    "\n",
    "for line in fileAN:\n",
    "    line = line.rstrip('\\n')\n",
    "    listAN.append(line)\n",
    "\n",
    "for line in fileDem:\n",
    "    line = line.rstrip('\\n')\n",
    "    listDem.append(line)\n",
    "\n",
    "for line in fileRel:\n",
    "    line = line.rstrip('\\n')\n",
    "    listRel.append(line)\n",
    "\n",
    "for line in filePhas:\n",
    "    line = line.rstrip('\\n')\n",
    "    listPhas.append(line)\n",
    "    \n",
    "an_vector_m1 = numpy.zeros(100)\n",
    "an_vector_m2 = numpy.zeros(100)\n",
    "an_vector_m3 = numpy.zeros(100)\n",
    "an_vector_m4 = numpy.zeros(100)\n",
    "an_vector_m5 = numpy.zeros(100)\n",
    "n_an=0\n",
    "\n",
    "dem_vector_m1 = numpy.zeros(100)\n",
    "dem_vector_m2 = numpy.zeros(100)\n",
    "dem_vector_m3 = numpy.zeros(100)\n",
    "dem_vector_m4 = numpy.zeros(100)\n",
    "dem_vector_m5 = numpy.zeros(100)\n",
    "n_dem=0\n",
    "\n",
    "rel_vector_m1 = numpy.zeros(100)\n",
    "rel_vector_m2 = numpy.zeros(100)\n",
    "rel_vector_m3 = numpy.zeros(100)\n",
    "rel_vector_m4 = numpy.zeros(100)\n",
    "rel_vector_m5 = numpy.zeros(100)\n",
    "n_rel=0\n",
    "\n",
    "phas_vector_m1 = numpy.zeros(100)\n",
    "phas_vector_m2 = numpy.zeros(100)\n",
    "phas_vector_m3 = numpy.zeros(100)\n",
    "phas_vector_m4 = numpy.zeros(100)\n",
    "phas_vector_m5 = numpy.zeros(100)\n",
    "n_phas=0\n",
    "\n",
    "for mCat in listAN:\n",
    "    m = \"NC:\"+mCat\n",
    "    if m not in model1.vocab:\n",
    "        continue\n",
    "    try:\n",
    "        m_vector_1 = model1[m.strip()]\n",
    "        an_vector_m1 = numpy.add(an_vector_m1,m_vector_m1)\n",
    "        m_vector_2 = model2[m.strip()]\n",
    "        an_vector_m2 = numpy.add(an_vector_m2,m_vector_m2)\n",
    "        m_vector_3 = model3[m.strip()]\n",
    "        an_vector_m3 = numpy.add(an_vector_m3,m_vector_m3)\n",
    "        m_vector_4 = model4[m.strip()]\n",
    "        an_vector_m4 = numpy.add(an_vector_m4,m_vector_m4)\n",
    "        m_vector_5 = model5[m.strip()]\n",
    "        an_vector_m5 = numpy.add(an_vector_m5,m_vector_m5)\n",
    "        n_an += 1\n",
    "    except KeyError as e:\n",
    "        continue \n",
    "an_vector_m1 = numpy.divide(an_vector_m1,n_an)\n",
    "an_vector_m2 = numpy.divide(an_vector_m2,n_an)\n",
    "an_vector_m3 = numpy.divide(an_vector_m3,n_an)\n",
    "an_vector_m4 = numpy.divide(an_vector_m4,n_an)\n",
    "an_vector_m5 = numpy.divide(an_vector_m5,n_an)\n",
    "\n",
    "for mCat in listDem:\n",
    "    m = \"NC:\"+mCat\n",
    "    if m not in model1.vocab:\n",
    "        continue\n",
    "    try:\n",
    "        m_vector_1 = model1[m.strip()]\n",
    "        dem_vector_m1 = numpy.add(dem_vector_m1,m_vector_m1)\n",
    "        m_vector_2 = model2[m.strip()]\n",
    "        dem_vector_m2 = numpy.add(dem_vector_m2,m_vector_m2)\n",
    "        m_vector_3 = model3[m.strip()]\n",
    "        dem_vector_m3 = numpy.add(dem_vector_m3,m_vector_m3)\n",
    "        m_vector_4 = model4[m.strip()]\n",
    "        dem_vector_m4 = numpy.add(dem_vector_m4,m_vector_m4)\n",
    "        m_vector_5 = model5[m.strip()]\n",
    "        dem_vector_m5 = numpy.add(dem_vector_m5,m_vector_m5)\n",
    "        n_dem += 1\n",
    "    except KeyError as e:\n",
    "        continue \n",
    "dem_vector_m1 = numpy.divide(dem_vector_m1,n_dem)\n",
    "dem_vector_m2 = numpy.divide(dem_vector_m2,n_dem)\n",
    "dem_vector_m3 = numpy.divide(dem_vector_m3,n_dem)\n",
    "dem_vector_m4 = numpy.divide(dem_vector_m4,n_dem)\n",
    "dem_vector_m5 = numpy.divide(dem_vector_m5,n_dem)\n",
    "\n",
    "for mCat in listRel:\n",
    "    m = \"NC:\"+mCat\n",
    "    if m not in model1.vocab:\n",
    "        continue\n",
    "    try:\n",
    "        m_vector_m1 = model1[m.strip()]\n",
    "        rel_vector_m1 = numpy.add(rel_vector_m1,m_vector_m1)\n",
    "        m_vector_m2 = model2[m.strip()]\n",
    "        rel_vector_m2 = numpy.add(rel_vector_m2,m_vector_m2)\n",
    "        m_vector_m3 = model3[m.strip()]\n",
    "        rel_vector_m3 = numpy.add(rel_vector_m3,m_vector_m3)\n",
    "        m_vector_m4 = model4[m.strip()]\n",
    "        rel_vector_m4 = numpy.add(rel_vector_m4,m_vector_m4)\n",
    "        m_vector_m5 = model5[m.strip()]\n",
    "        rel_vector_m5 = numpy.add(rel_vector_m5,m_vector_m5)\n",
    "        n_rel += 1\n",
    "    except KeyError as e:\n",
    "        continue \n",
    "rel_vector_m1 = numpy.divide(rel_vector_m1,n_rel)\n",
    "rel_vector_m2 = numpy.divide(rel_vector_m2,n_rel)\n",
    "rel_vector_m3 = numpy.divide(rel_vector_m3,n_rel)\n",
    "rel_vector_m4 = numpy.divide(rel_vector_m4,n_rel)\n",
    "rel_vector_m5 = numpy.divide(rel_vector_m5,n_rel)\n",
    "\n",
    "for mCat in listPhas:\n",
    "    m = \"NC:\"+mCat\n",
    "    if m not in model1.vocab:\n",
    "        continue\n",
    "    try:\n",
    "        m_vector_m1 = model1[m.strip()]\n",
    "        phas_vector_m1 = numpy.add(phas_vector_m1,m_vector_m1)\n",
    "        m_vector_m2 = model2[m.strip()]\n",
    "        phas_vector_m2 = numpy.add(phas_vector_m2,m_vector_m2)\n",
    "        m_vector_m3 = model3[m.strip()]\n",
    "        phas_vector_m3 = numpy.add(phas_vector_m3,m_vector_m3)\n",
    "        m_vector_m4 = model4[m.strip()]\n",
    "        phas_vector_m4 = numpy.add(phas_vector_m4,m_vector_m4)\n",
    "        m_vector_m5 = model5[m.strip()]\n",
    "        phas_vector_m5 = numpy.add(phas_vector_m5,m_vector_m5)\n",
    "        n_phas += 1\n",
    "    except KeyError as e:\n",
    "        continue \n",
    "phas_vector_m1 = numpy.divide(phas_vector_m1,n_phas)\n",
    "phas_vector_m2 = numpy.divide(phas_vector_m2,n_phas)\n",
    "phas_vector_m3 = numpy.divide(phas_vector_m3,n_phas)\n",
    "phas_vector_m4 = numpy.divide(phas_vector_m4,n_phas)\n",
    "phas_vector_m5 = numpy.divide(phas_vector_m5,n_phas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computation of the average proximity scores of candidates to agentivity to ANs and HNs centroids\n",
    "# Requires the loading of the list of candidates (see 2nd cell) - listCandidat below\n",
    "\n",
    "for mCat in listCandidat:\n",
    "    m = \"NC:\"+mCat\n",
    "    if m not in model1.vocab:\n",
    "        continue\n",
    "    try:\n",
    "        d1_m1 = abs(numpy.divide(numpy.dot(model1[m.strip()],an_vector_m1),numpy.dot(numpy.linalg.norm(model1[m.strip()]),numpy.linalg.norm(an_vector_m1))))\n",
    "        d1_m2 = abs(numpy.divide(numpy.dot(model2[m.strip()],an_vector_m2),numpy.dot(numpy.linalg.norm(model2[m.strip()]),numpy.linalg.norm(an_vector_m2))))\n",
    "        d1_m3 = abs(numpy.divide(numpy.dot(model3[m.strip()],an_vector_m3),numpy.dot(numpy.linalg.norm(model3[m.strip()]),numpy.linalg.norm(an_vector_m3))))\n",
    "        d1_m4 = abs(numpy.divide(numpy.dot(model4[m.strip()],an_vector_m4),numpy.dot(numpy.linalg.norm(model4[m.strip()]),numpy.linalg.norm(an_vector_m4))))\n",
    "        d1_m5 = abs(numpy.divide(numpy.dot(model5[m.strip()],an_vector_m5),numpy.dot(numpy.linalg.norm(model5[m.strip()]),numpy.linalg.norm(an_vector_m5))))\n",
    "        d1 = (d1_m1 + d1_m2 + d1_m3 + d1_m4 + d1_m5)/5\n",
    "\n",
    "        d2_m1 = abs(numpy.divide(numpy.dot(model1[m.strip()],phas_vector_m1),numpy.dot(numpy.linalg.norm(model1[m.strip()]),numpy.linalg.norm(phas_vector_m1))))\n",
    "        d2_m2 = abs(numpy.divide(numpy.dot(model2[m.strip()],phas_vector_m2),numpy.dot(numpy.linalg.norm(model2[m.strip()]),numpy.linalg.norm(phas_vector_m2)))) \n",
    "        d2_m3 = abs(numpy.divide(numpy.dot(model3[m.strip()],phas_vector_m3),numpy.dot(numpy.linalg.norm(model3[m.strip()]),numpy.linalg.norm(phas_vector_m3)))) \n",
    "        d2_m4 = abs(numpy.divide(numpy.dot(model4[m.strip()],phas_vector_m4),numpy.dot(numpy.linalg.norm(model4[m.strip()]),numpy.linalg.norm(phas_vector_m4)))) \n",
    "        d2_m5 = abs(numpy.divide(numpy.dot(model5[m.strip()],phas_vector_m5),numpy.dot(numpy.linalg.norm(model5[m.strip()]),numpy.linalg.norm(phas_vector_m5)))) \n",
    "        d2 = (d2_m1 + d2_m2 + d2_m3 + d2_m4 + d2_m5)/5\n",
    "\n",
    "        d3_m1 = abs(numpy.divide(numpy.dot(model1[m.strip()],rel_vector_m1),numpy.dot(numpy.linalg.norm(model1[m.strip()]),numpy.linalg.norm(rel_vector_m1)))) \n",
    "        d3_m2 = abs(numpy.divide(numpy.dot(model2[m.strip()],rel_vector_m2),numpy.dot(numpy.linalg.norm(model2[m.strip()]),numpy.linalg.norm(rel_vector_m2)))) \n",
    "        d3_m3 = abs(numpy.divide(numpy.dot(model3[m.strip()],rel_vector_m3),numpy.dot(numpy.linalg.norm(model3[m.strip()]),numpy.linalg.norm(rel_vector_m3)))) \n",
    "        d3_m4 = abs(numpy.divide(numpy.dot(model4[m.strip()],rel_vector_m4),numpy.dot(numpy.linalg.norm(model4[m.strip()]),numpy.linalg.norm(rel_vector_m4)))) \n",
    "        d3_m5 = abs(numpy.divide(numpy.dot(model5[m.strip()],rel_vector_m5),numpy.dot(numpy.linalg.norm(model5[m.strip()]),numpy.linalg.norm(rel_vector_m5))))\n",
    "        d3 = (d3_m1 + d3_m2 + d3_m3 + d3_m4 + d3_m5)/5\n",
    "\n",
    "        d4_m1 = abs(numpy.divide(numpy.dot(model1[m.strip()],dem_vector_m1),numpy.dot(numpy.linalg.norm(model1[m.strip()]),numpy.linalg.norm(dem_vector_m1)))) \n",
    "        d4_m2 = abs(numpy.divide(numpy.dot(model2[m.strip()],dem_vector_m2),numpy.dot(numpy.linalg.norm(model2[m.strip()]),numpy.linalg.norm(dem_vector_m2)))) \n",
    "        d4_m3 = abs(numpy.divide(numpy.dot(model3[m.strip()],dem_vector_m3),numpy.dot(numpy.linalg.norm(model3[m.strip()]),numpy.linalg.norm(dem_vector_m3)))) \n",
    "        d4_m4 = abs(numpy.divide(numpy.dot(model4[m.strip()],dem_vector_m4),numpy.dot(numpy.linalg.norm(model4[m.strip()]),numpy.linalg.norm(dem_vector_m4)))) \n",
    "        d4_m5 = abs(numpy.divide(numpy.dot(model5[m.strip()],dem_vector_m5),numpy.dot(numpy.linalg.norm(model5[m.strip()]),numpy.linalg.norm(dem_vector_m5)))) \n",
    "        d4 = (d4_m1 + d4_m2 + d4_m3 + d4_m4 + d4_m5)/5\n",
    "        print(mCat, d1, d2, d3, d4)\n",
    "    except KeyError as e:\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
